---
title: "R Commands for MATH 204"
author: "JMG"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
---

```{r,echo=FALSE}
set.seed(1234)
```

# Some Useful R Commands

This notebook illustrates some R commands that relate directly to the statistical concepts covered in [MATH 204](https://math204fall2021.netlify.app/) *Introduction to Statistics*. The presentation is terse and there is little discussion on how to interpret results as these details are covered in lectures. 

## Loading Packages

It is necessary to load any package (other than base R) that contains commands that we want to use. Note that these packages have to be installed before they can be loaded. One can install packages using the "Packages" tab and then clicking the "Install" icon.

```{r,warning=FALSE,message=FALSE}
# load packages
library(tidyverse)
library(openintro)
library(ggformula)
library(ggmosaic)
library(broom)
library(GGally)
library(skimr)
```

Here is a brief overview on each of the packages we have loaded:

-   [`tidvyverse`](https://www.tidyverse.org/) contains commands for working with data frames and creating plots with [`ggplot`](https://ggplot2.tidyverse.org/),

- [`openintro`](https://github.com/OpenIntroStat/openintro) is an R package that is associated with our textbook [OpenIntro Statistics](https://openintro.org/book/os/). Mostly it just contains data sets. 

- [`ggformula`](http://www.mosaic-web.org/ggformula/reference/ggformula.html), [`ggmosaic`](https://cran.r-project.org/web/packages/ggmosaic/vignettes/ggmosaic.html), and [`GGally`](https://ggobi.github.io/ggally/) each add enhanced plotting capabilities,

- [`broom`](https://cran.r-project.org/web/packages/broom/vignettes/broom.html) has commands that help clean up output from linear models,

- [`skimr`](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html) contains a command called `skim` that prints out a nice data summary. 

Now that we've loaded our packages, we can import some data. 

## Load the Data

Here we load some data, the EPA 2021 vehicle data.

```{r}
# load data
my_data <- read.csv("epa2021data.csv")
# if you don't have the data file, uncomment and use:
#my_data <- epa2021
```

This data contains vehicle information from the EPA for 2021. The size of this data set is reported by the following command:


```{r}
dim(my_data)
```


We see that there are 1108 observations (rows) and 28 variables (columns). 

It is a good idea to try to learn more about our data set. One helpful command along these lines is the `summary` command that prints out summary statistics for each variable in the data set. 

```{r}
summary(my_data)
```


One benefit of the summary command is that it helps us to identify the type of each variable. The `glimpse` command from the `pillar` package (which is installed as part of `tidyverse`) is also helpful in this regard. 

```{r}
pillar::glimpse(my_data)
```


The next step in a data analysis is to conduct a so-called exploratory data analysis (EDA). This allows us to assess the data for any problems and also helps to suggest what types of statistical or analytical questions can be asked and/or answered. 

The first steps in EDA are to compute summary statistics for variables of interest and to build appropriate summary visualizations.   

## Summary Stats for a Numerical Variable

For example, the `comb_mpg` variable (combined mileage) is a continuous numerical variable so it makes sense to compute its mean, median, standard deviation, and variance.  

```{r}
(comb_mpg_mean <- mean(my_data$comb_mpg))
(comb_mpg_median <- median(my_data$comb_mpg))
(comb_mpg_sd <- sd(my_data$comb_mpg))
(comb_mpg_var <- var(my_data$comb_mpg))
```

## Visual Summaries for Numerical Variables

Histograms and boxplots are appropriate ways to provide a visual summary for a numerical variable. The following plotting commands illustrate some of the ways in which such plots can be obtained.   

```{r}
gf_histogram(~comb_mpg,data=my_data)
```

Let's change the number of bins and also add color to show where the bins are.

```{r}
gf_histogram(~comb_mpg,data=my_data,bins=25,color="black")
```

A boxplot is another way to visualize numerical data.

```{r}
gf_boxplot(~comb_mpg,data=my_data) + coord_flip()
```

## Inference for Proportions and Means

The following subsections illustrate the R commands for conducting a statistical hypothesis test for a single proportion, a difference of proportions, a single mean, paired means, and a difference of two means. Only the syntax is illustrated, refer to the lectures for more context.  

### Single Proportion

```{r}
prop.test(18,45,p=0.32,correct = FALSE)
```

To conduct the same test "by hand," we use

```{r}
n <- 45
p_hat <- 18/n
p0 <- 0.32
SE <- sqrt((p0*(1-p0))/n)
(z_val <- (p_hat-p0)/SE )
(p_val <- 2*(1-pnorm(z_val))) # since 2-sided and z_val > 0
```

### Difference of Proportions

```{r}
prop.test(c(18,15),c(45,27),correct=FALSE)
```

To conduct the same test "by hand," we use

```{r}
n1 <- 45
n2 <- 27
p_hat1 <- 18/n1
p_hat2 <- 15/n2
p_pooled <- (p_hat1*n1 + p_hat2*n2)/(n1+n2)
SE <- sqrt((p_pooled*(1-p_pooled))/n1 + (p_pooled*(1-p_pooled))/n2)
(z_val <- (p_hat1-p_hat2)/SE)
(p_val <- 2*pnorm(z_val)) # since 2-sided and z_val < 0 
```

### Single Mean

```{r}
sim_data <- tibble(x=rnorm(18,2,0.75),y=rnorm(18,2.2,0.75))

t.test(sim_data$x,mu=1)
```

To conduct this test "by hand", use

```{r}
n <- length(sim_data$x)
mu_x <- mean(sim_data$x)
sd_x <- sd(sim_data$x)
SE <- sd_x/sqrt(n)
mu0 <- 1
(t_val <- (mu_x-mu0)/SE)
(p_val <- 2*(1-pt(t_val,df=n-1))) # since 2-sided and t_val > 0
```


### Paired Samples

```{r}
t.test(sim_data$x,sim_data$y,paired = TRUE)
```

To conduct this test "by hand", use

```{r}
xy_diff <- sim_data$x - sim_data$y
n <- length(xy_diff)
mu_diff <- mean(xy_diff)
sd_diff <- sd(xy_diff)
SE <- sd_diff/sqrt(n)
(t_val <- mu_diff/SE)
(p_val <- 2*pt(t_val,df=n-1)) # since 2-sided and t_val < 0
```

### Difference of Means


```{r}
z <- rnorm(22,2,0.75)

t.test(sim_data$x,z,paired=FALSE)
```

To do this test "by hand", use

```{r}
n1 <- length(sim_data$x)
n2 <- length(z)
mu_1 <- mean(sim_data$x)
sd_1 <- sd(sim_data$x)
mu_2 <- mean(z)
sd_2 <- sd(z)
mu_diff <- mu_1 - mu_2
SE <- sqrt(sd_1^2/n1 + sd_2^2/n2)
(t_val <- (mu_diff)/SE)
(p_val <- 2*(1-pt(t_val,df=min(n1-1,n2-1)))) # since 2-sided and t_val > 0
```

**Note:** The results are slightly different from what we see with the `t.test` command. This is due to the fact that the `t.test` implementation utilizes a pooled standard deviation which is a special topic that we did not cover in lecture. 

## Summary Stats for a Categorical Variable

For a single categorical variable, a one-way table is used to summarize the counts for how many times each level of the variable occurs as an observation in the sample data. For example, 

```{r}
table(my_data$drive_desc)
```

The `addmargins` command totals the counts.

```{r}
addmargins(table(my_data$drive_desc))
```


Instead of counts, we can also compute proportions.

```{r}
proportions(table(my_data$drive_desc))
```

or with the total

```{r}
addmargins(proportions(table(my_data$drive_desc)))
```


## Visual Summaries for a Single Categorical Variable

A visualization that corresponds to a one-way table is provided by a bar plot.

```{r}
gf_bar(~drive_desc,data=my_data)
```

Note that the x-axis labels are difficult to read. This can be addressed as follows.

```{r}
gf_bar(~drive_desc,data=my_data) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

The proportions version of a bar plot is obtained with a mosaic plot.

```{r}
ggplot(data = my_data) +
  geom_mosaic(aes(x = product(drive_desc), fill=drive_desc))
```

or with easier to read labeling:

```{r}
ggplot(data = my_data) +
  geom_mosaic(aes(x = product(drive_desc), fill=drive_desc)) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```



## Variable Associations

Sometimes we are interested in the association of two variables. There are three typical situations:

1) Two numerical variables. To study this, we use correlation, scatter plots, and regression.

2) One numerical variable (as response) and one categorical variable (as explanatory). To study this, we use grouped summaries, side-by-side boxplots, and two-sample t-tests (when categorical variable is binary) or ANOVA. 

3) Two categorical variables. Here, we use two-way tables, mosaic plots, and chi-square tests. 

### Two Numeric Variables

Consider for example, the variables `comb_mpg` (combined mileage) and `engine_displacement` (engine displacement). We may want to know if fuel efficiency is realted to engine size. 

The correlation of these two variables is

```{r}
(R_val <- cor(my_data$engine_displacement,my_data$comb_mpg))
```

This value squared is $R^2$:

```{r}
R_val^2
```


Let's examine the scatter plot for these variables:

```{r}
# scatterplot for two numerical variables
gf_point(comb_mpg~engine_displacement,data=my_data)
```


If we want to include the regression line, it can be added as follows:
```{r}
gf_point(comb_mpg~engine_displacement,data=my_data) %>%
  gf_lm()
```

The following code fits a linear model for these variables and returns the inferential statistics:

```{r}
lm_fit <- lm(comb_mpg~engine_displacement,data=my_data)
summary(lm_fit)
```

We can clean this output up using the commands from the `broom` package. For example,

```{r}
tidy(lm_fit)
```
outputs the parameter estimates, standard errors, and p-values for the intercept and slope parameters. The `glance` command provides additional information such as the $R^2$ value and the degrees of freedom `df.residual` (notice that this is $n-2$ where $n$ is the number of observations).  

```{r}
glance(lm_fit)
```

Residual plots are very helpful to assess potential issues with a linear fit. Here is code that produces a residual plot. Note that the first step is to obtain the residuals using the `augment` function.

```{r,message=FALSE,warning=FALSE}
lm_fit %>% augment() %>%
  gf_point(.resid~engine_displacement) %>% gf_hline(yintercept = 0,linetype="dashed")
```

Note that the residuals are not evenly distributed around the 0 line which indicates that a linear model is not appropriate for this data. 

### Numerical Response and Categorical Explanatory

How does the distribution of a numerical variable depend on the category to which the samples belong? For example, how does the combined gas mileage depend on what kind of drive system a vehicle uses? 

We can compute grouped summary statistics. For example, the mean gas mileage per class of drive system is computed as follows:

```{r}
my_data %>% group_by(drive_desc) %>% summarise(mean_comb_mpg=mean(comb_mpg))
```

A side-by-side boxplot allows us to see the distribution of a numerical variable by category. 

```{r}
gf_boxplot(comb_mpg~drive_desc,data=my_data)
```

or

```{r}
gf_boxplot(comb_mpg~drive_desc,data=my_data) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

#### Inference with ANOVA

In order to test if the observed difference in means is likely true, or is simply a result of sampling, we use an ANOVA. This is conducted as follows:

```{r}
summary(aov(comb_mpg~drive_desc,data=my_data))
```

### Association for a Pair of Categorical Variables

A two-way or cross table compares combinations of categories for two categorical variables. For example, conside the data set `hsb2` from the `openintro` package which records samples from the High School and Beyond survey, a survey conducted on high school seniors by the National Center of Education Statistics.

```{r}
table(hsb2$ses,hsb2$prog)
```

We can also add the margin sum totals

```{r}
addmargins(table(hsb2$ses,hsb2$prog))
```

Here `ses` is the socio economic status of student's family  and `prog` is the type of program.  

A mosaic plot can be used to visualize this data.

```{r}
ggplot(data = hsb2) +
  geom_mosaic(aes(x = product(ses, prog), fill=ses)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

#### Inference with chi-square

We can ask if the variables `ses` and   `prog` are independent. A chi-square test helps to answer this. 

```{r}
chisq.test(hsb2$ses,hsb2$prog)
```

## Working with Distributions.  

In order to conduct hypothesis test "by hand", it helpful to be able to work with the basic distribution functions in R. For each distribution there are four functions:

1) `r_dist_name` which draws random samples

2) `d_dist_name` which represents the density function or probability mass function

3) `p_dist_name` which represents the cumulative distribution function, this is used to compute left-tail areas

4) `q_dist_name` is the quantile function which is the inverse function of `p_dist_name`

Suppose for example that we want to work with a normal distribution. Then we replace `_dist_name` with `norm`. For example, 

```{r}
(sim_x <- rnorm(75,10,2.5))
```

Let's make a histogram of this data:

```{r}
gf_histogram(~sim_x,binwidth = 1.0,color="black")
```

Here are illustrations of the uses of the other distribution functions:


The value of the standard normal density function at $z=0$ is 
```{r}
dnorm(0.0)
```


Let's plot the standard normal density curve:
```{r}
gf_dist("norm")
```

The use of the `p` and `q` functions are illustrated with

```{r}
pnorm(1.5)
```

and 

```{r}
qnorm(0.3)
```

**Note** Depending on the type of distribution you want to work with, you need to specify appropriate values for an parameters. For example, to work with a t distribution to need to specify the appropriate values for the degrees of freedom `df`. 


## Two Bonus Commands


### Data Summary with skim

An even fancier summary of our data is provided by the `skim` function from the `skimr` package. Let's see how it works.

```{r}
skimr::skim(my_data)
```

Essentially what this shows is that we have 20 categorical variables and 8 numerical variables. For each of the numerical variables, the `skim` function reports all of the quantitative summary statistic values. 

### Mulitple Scatter Plots with ggpairs

We might want to study the associations of multiple numerical variables simultaneously. The `ggpairs` command from the `GGally` package is a way to obtain a lot of information about several numerical varaibles with one plot. For example, 

```{r,message=FALSE,warning=FALSE}
GGally::ggpairs(my_data[,c(6,7,8,12)])
```



