---
title: "Lecture 11"
subtitle: " "
author: "JMG"
institute: "MATH 204"
output:
  xaringan::moon_reader:
    css: [rladies, rladies-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(openintro)
library(faraway)
library(tidyverse)
library(ggformula)
library(ggmosaic)
library(patchwork)
library(latex2exp)
library(kableExtra)
library(broom)
```


# Inference for Categorical Data

In this lecture, we will examine two new inferential techniques:

--

- Testing for goodness of fit using chi-square, which is applied to a categorical variable with more than two levels. This is commonly used in two circumstances:

--

  - Given a sample of cases that can be classified into several groups, determine if the sample is representative of the general population. 
  
--

  - Evaluate whether data resemble a particular distribution, such as a normal distribution or a geometric distribution. 
  
--

- Testing for independence in two-way tables. 

---

# Learning Objectives

- In this lecture, we cover some inferential techniques for categorical data. After this lecture you should be able to

--

  - Identify one-way and two-way table problems.
  
--

  - Work with a chi-square statistic and distribution.
  
--

  - Use the `aov` function in R to conduct hypothesis tests. 
---

# Video on Goodness of Fit

```{r,echo=FALSE}
vembedr::embed_url("https://youtu.be/Uk36WGxujkc") %>%
  vembedr::use_align("center")
```

---

# Video on Two-Way Tables


```{r,echo=FALSE}
vembedr::embed_url("https://youtu.be/yjrsfNdja0U") %>%
  vembedr::use_align("center")
```

---

# Motivating Example

Consider the following data:

--

```{r,echo=FALSE}
race_counts <- jury %>% group_by(race) %>% summarise(n=n())
jury_tb <- tibble(race=c("Representation in juries","Registered voters"),black=c(26,0.07),hispanic=c(25,0.12),white=c(205,0.72),other=c(19,0.09)) %>% mutate(total=black+hispanic+white+other)
jury_tb %>% kbl() %>% kable_styling()
```

--

We can compute the proportions for the data:

```{r,echo=FALSE}
race_counts %>% mutate(p = n/sum(n))
```

--

- We would like to know if the jury is representative of the population.

--

- This problem illustrates "Given a sample of cases that can be classified into several groups, determine if the sample is representative of the general population."

---

# One-Way Tables

- If we were to take the bottom row of the table on the last slide as the assumed true proportions, then we would expect to get the following so-called **one-way table**:

```{r,echo=FALSE}
jury_owtb <- tibble(race=c("Observed count","Expected count"),black=c(26,19.25),hispanic=c(25,33),white=c(205,198),other=c(19,24.75)) %>% mutate(total=black+hispanic+white+other)
jury_owtb %>% kbl() %>% kable_styling()
```

--

- From a one-way table we can produce a test statistic that follows a well-known distribution. Specifically, we compute

$$\frac{(26-19.25)^2}{19.25} + \frac{(25-33)^2}{33} + \frac{(205-198)^2}{198} + \frac{(19-24.75)^2}{24.75}$$

--

- This value is

```{r}
(26-19.25)^2/19.25 + (25-33)^2/33 + (205-198)^2/198 + (19-24.75)^2/24.75
```

---

# chi-Square Distributions

- In order to conduct inferences on data corresponding to one-way tables, we need to use a new distribution function called a **chi-square distribution**. Such distributions are characterized by a parameter called degrees of freedom. Below we plot a chi-square density function with 3 degrees of freedom:

```{r,fig.height=5}
gf_dist("chisq",df=3)
```


---

# chi-Square for Different df's

```{r,echo=FALSE,fig.height=6,fig.width=10,warning=FALSE,message=FALSE}
lab1 <- TeX("$df = 2$")
lab2 <- TeX("$df = 4$")
lab3 <- TeX("$df = 9$")

ggplot(data.frame(x = c(0, 25)), aes(x)) + 
  stat_function(fun = dchisq, args = list(df = 2), col='#88CCEE',lwd=1) +
  stat_function(fun = dchisq, args = list(df=4), col='#CC6677',lwd=1) + stat_function(fun = dchisq, args = list(df=9), col='#DDCC77',lwd=1) +
  annotate(geom="text",x=2.5,y=0.3,label=lab1,col="#88CCEE",size=6) + 
  annotate(geom="text",x=4,y=0.18,label=lab2,col="#CC6677",size=6) + 
  annotate(geom="text",x=12,y=0.1,label=lab3,col="#DDCC77",size=6)
```

---

# chi-Square Test Conditions

- In order to use a chi-square distribution to compute a p-value, we need to check two conditions:

--

  - Independence. Each case that contributes a count to the table must be independent of all the other cases in the table. 
  
--

  - Sample size / distribution. Each particular scenario must have at least 5 expected cases. 


---

# chi-Square Test for One-Way Table

Suppose we are to evaluate whether there is convincing evidence that a set of observed counts $O_{1}$, $O_{2}$, $\ldots$, $O_{k}$ in $k$ categories are unusually different from what we might expect under a null hypothesis. Denote the *expected counts* that are based on the null hypothesis by $E_{1}$, $E_{2}$, $\ldots$, $E_{k}$. If each expected count is at least 5 and the null hypothesis is true, then the test statistic

$$X^{2} = \frac{(O_{1}-E_{1})^2}{E_{1}} + \frac{(O_{2}-E_{2})^2}{E_{2}} + \cdots + \frac{(O_{k}-E_{k})^2}{E_{k}}$$
follows a chi-square distribution with $k-1$ degrees of freedom. Note that this test statistic is always positive. 

--

The p-value for this test statistic is found by looking at the upper tail of this chi-square distribution. We consider the upper tail because larger values of $X^2$ would provide greater evidence against the null hypothesis. 


---

# Example chi-Square Test

- We expect the statistic for the one-way table for the jury data to follow a chi-square distribution with 3 degrees of freedom since there are $k=4$ categories. 

--

- Then the probability of observing a value that is as or more extreme that the value obtained from the sample data is

```{r}
1 - pchisq(5.89,3)
```

--

- Alternatively:

```{r}
pchisq(5.89,3,lower.tail = FALSE)
```

--

- We just computed a p-value, but to what null hypothesis does this p-value provide an appropriate means of testing? 

---

# Null Hypothesis for One-Way Tables

- In our example, we would want to test:

--

  - $H_{0}:$ The jurors are a random sample, that is, there is no racial bias in who serves on a jury, and the observed counts reflect natural sampling fluctuation. 
  
--

  - $H_{A}:$ The jurors are not randomly sampled, that is, there is racial bias in juror selection. 
  
--

- Using the data, we can conduct the chi-square test as follows:

```{r}
chisq.test(c(26,25,205,19),p=c(0.07,0.12,0.72,0.09))
```

---

# More Examples

- Let's see some more examples.

--

- Let's look at exercise 6.33 frmo the textbook on page 239. The table for the data will look as follows:

```{r,echo=FALSE}
open_tb <- tibble(textbook=c("Method","Expected percent"),purchased=c(71,0.6),printed=c(30,0.25),online=c(25,0.15)) %>% mutate(total=purchased+printed+online)
open_tb %>% kbl() %>% kable_styling()
```

--

- The expected counts will be

```{r,echo=FALSE}
c(purchased=0.6*126,printed=0.25*126,online=0.15*126)
```

--

- Thus, our $X^2$ statistic is

```{r}
(X2 <- (71-75.6)^2/75.6  + (30-31.5)^2/31.5  + (25-18.9)^2/18.9)
```


---

# Example Continued

- The appropriate degrees of freedom is 2. Therefore, the tail area is

```{r}
pchisq(X2,2,lower.tail = FALSE)
```

--

- If our hypothesis is: $H_{0}:$ the distribution of the format of the book used follows the expected distribution, vs. $H_{A}:$ the distribution of the format of the book used does not follow the expected distribution, then we will fail to reject the null hypothesis at the $\alpha = 0.05$ level of significance. 

--

- We can confirm our result using R:

```{r}
chisq.test(c(71,30,25),p=c(0.6,0.25,0.15))
```

---

# Two-Way Tables

- A one-way table describes counts for each outcome in a single categorical variable. 

--

- A two-way table describes counts for combinations of two categorical variables where at least one of the two has more than 2 levels.  

--

- When we consider a two-way table, we often would like to know, are these variables related in any way? That is, are they dependent versus independent? 


---

# Null Hypothesis for Two-Way Tables

- For a two-way table problem, the typical hypotheses are of the form

--

  - $H_{0}:$ The two variables are independent. 
  
--

  - $H_{A}:$ The two variables are dependent. 

--

- Let's look at an example. 

---

# Offshore Drilling Example

- Consider the data with first few rows shown below:

```{r,echo=FALSE}
offshore_drilling_c <- offshore_drilling[2:nrow(offshore_drilling), ]
pos <- as.character(offshore_drilling_c$v1)
college <- as.character(offshore_drilling_c$v2)
my_offshore_drilling <- tibble(position=factor(pos),college_grad=factor(college))
head(my_offshore_drilling)
```

--

- Let's look at the corresponding two-way table:

```{r}
addmargins(table(my_offshore_drilling$position,my_offshore_drilling$college_grad))
```

---

# Hypothesis Test for Offshore Drilling

- We would like to test the hypothesis:

--

  - $H_{0}:$ College graduate status and support for offshore drilling are independent. 
  
--

  - $H_{A}:$ College graduate status and support for offshore drilling are not independent. 
  
--

- This is easily done with

```{r}
chisq.test(my_offshore_drilling$position,my_offshore_drilling$college_grad)
```


--

- Thus, we will reject the null hypothesis at the $\alpha=0.05$ significance level.

---

# Tests By Hand

- Let's see how to conduct the previous test by hand. 

--

- The two things we need to know are the value of the $X^2$ statistic and the appropriate number of degrees of freedom to use. 

--

- When applying the chi-square test to a two-way table, we use

$$df = (R-1) \times (C-1)$$

where $R$ is the number of rows in the table and $C$ is the number of columns. 

--

- Thus, in our example, $df = (3-1)\times (2-1) = 2$.

---

# Computing $X^2$

- As before

$$X^2 = \sum \frac{(O-E)^2}{E}$$

--

- The question is, how do we compute the expected counts ( $E_{ij}$ ) for a two-way table? The answer is

$$\text{Expected Count}_{\text{row }i \text{ col }j} = E_{ij} = \frac{\text{row }i \text{ total} \times \text{column }j \text{ total}}{\text{table total}}$$

--

- Let's work this out on the board for our example. 

---

# Hypothesis Testing Summary

- To date, we have covered the following tests:

--

  - Single proportion and difference of proportions using a "z-test."
  
--

  - Single mean, paired mean, difference of means using a "t-test."
  
--

  - Comparing many means with ANOVA.
  
--

  - One-way and two-way table tests for categorical variables with chi-square. 
  
--

 - Simple linear regression via ordinary least squares for a pair of numeric variable. 
 
--

- We also know how to construct confidence intervals for parameter estimates for proportions, difference of proportions, mean, difference of means, and intercept and slope parameters for a linear model. 

---

# Next Topic

- Our next topic discusses more regarding regression. This video will get you started:

```{r,echo=FALSE}
vembedr::embed_url("https://youtu.be/sQpAuyfEYZg") %>%
  vembedr::use_align("center")
```
