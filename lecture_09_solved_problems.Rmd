---
title: "Lecture 9 Solved Problems"
author: "JMG"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(openintro)
library(tidyverse)
library(ggformula)
library(ggmosaic)
```


## Single Proportion Problems

### Parking Problem CI

> Is parking a problem on campus? A randomly selected group of 89 faculty and staff are asked whether they are satisfied with campus parking or not. Of the 89 individuals surveyed, 23 indicated that they are satisfied. What is the proportion $p$ of faculty and staff that are satisfied with campus parking?

The data corresponds to a sample proportion. Let's check the success-failure condition. Our point estimate $\hat{p}$ is
```{r}
(p_hat <- 23 / 89)
```

Then, 
```{r}
n <- 89 # sample size
(n*p_hat)
(n*(1-p_hat))
```

We see that the success-failure condition is met. 

The plug-in principle gives the following estimate for standard error:
```{r}
(SE <- sqrt((p_hat*(1-p_hat))/n))
```

Then a 95% confidence interval (CI) is
```{r}
p_hat + 1.96 * c(-1,1) * SE
```

Thus, around 95% of the time we expect that our estimate will be between 0.167 and 0.349. 

### Exercise 6.7

Our sample size and point estimate is
```{r}
(n <- 600)
(p_hat <- 0.56)
```

We check the success-failure condition
```{r}
(n*p_hat)
(n*(1-p_hat))
```

and see that it is met. Then, the margin of error for a 95% CI is
```{r}
(SE <- sqrt((p_hat*(1-p_hat))/n))
(marg_err <- 1.96*SE)
```

So a 95% CI is
```{r}
p_hat + c(-1,1)*marg_err
```

### Exercise 6.13

Our sample size and point estimate is
```{r}
(n <- 80)
(p_hat <- 53 / n)
```

Our null hypothesis is 

$H_{0}: p = 0.5$ That is, people can  not tell the difference between diet and regular soda. 

and our alternative hypothesis is

$H_{A}: p\neq 0.5$ That is, people can tell the difference between diet and regular soda

We check the success-failure condition with the $p_{0}=0.5$
```{r}
p0 <- 0.5
(n*p0)
(n*(1-p0))
```

We conclude that the success-failure condition is met. Now we obtain our standard error and z-score
```{r}
SE <- sqrt((p0*(1-p0))/n)
(z_score <- (p_hat - p0)/SE)
```

Then, our p-value will be the probability of obtaining a value that is as or more extreme than our observation. This is computed as
```{r}
2*(1 - pnorm(z_score))
```

Since this is less than $\alpha = 0.05$ we will reject the null hypothesis at the 0.05 significance level. Alternatively, we can use `prop.test`
```{r}
prop.test(53,80,p=0.5,correct = FALSE)
```

If it is true that people can not tell the difference between diet and regular soda, then we expect to obtain a result that is as or more extreme than 53 people correctly identifying the soda less than 0.4% of the time. 


## Difference of Proportion Problems

### 6.19

(a) False. Since $(p_{\text{male}} - p_{\text{female}}) > 0$, the proportion of males whose favorite color is black is higher than the proportion of females. 

(b) True. 

(c) True.

(d) True. 

(e) False. All you have to do is change signs. 

### 6.23

Here's what our data looks like:
```{r}
support_drilling <- c(rep("Yes",154),rep("No",180),rep("Do not know",104),rep("Yes",132),rep("No",126),rep("Do not know",131))
college_grad <- c(rep("Yes",438),rep("No",389))
college_grad <- factor(college_grad,levels=c("Yes","No"))
my_df <- tibble(support_drilling=support_drilling,college_grad=college_grad)
my_df %>% slice_sample(n=6)
```

A visualization:

```{r}
my_df %>% 
  ggplot() + 
  geom_mosaic(aes(x = product(support_drilling,college_grad), fill=support_drilling))
```

(a) 
```{r}
(p1 <- 104/438)
(p2 <- 131/389)
```



(b) First, we will conduct a hypothesis test using the `prop.test` command:
```{r}
prop.test(c(104,131),c(438,389),correct = FALSE)
```

In this case, we will reject the null hypothesis at the $\alpha = 0.05$ significance level since out p-value is 0.001573 which is less than 0.05. 

Now, the long way:
```{r}
n1 <- 438
n2 <- 389
p_diff <- p1 - p2
p_pooled <- (p1*n1 + p2*n2)/(n1 + n2)
(c(n1*p1,n1*(1-p1),n2*p2,n2*(1-p2)))
SE <- sqrt((p_pooled*(1-p_pooled))/n1 + (p_pooled*(1-p_pooled))/n2)
(z_val <- (p_diff - 0.0)/SE)
```

Compute the p-value
```{r}
(p_value <- 2*pnorm(-3.1608))
```

In this case, we will reject the null hypothesis at the $\alpha = 0.05$ significance level since out p-value is 0.001573 which is less than 0.05.


## One-Sample Means Problems 

### 7.1

(a)

```{r}
n <- 6
confidence_level <- 0.9
(t_ast <- -qt((1.0 - confidence_level)/2,df=n-1))
```

(b)

```{r}
n <- 21
confidence_level <- 0.98
(t_ast <- -qt((1.0 - confidence_level)/2,df=n-1))
```

(c)

```{r}
n <- 29
confidence_level <- 0.95
(t_ast <- -qt((1.0 - confidence_level)/2,df=n-1))
```

(d)

```{r}
n <- 12
confidence_level <- 0.99
(t_ast <- -qt((1.0 - confidence_level)/2,df=n-1))
```

### 7.4

(a)

```{r}
2*(1-pt(2.485,25))
```

Do not reject.

(b)

```{r}
2*(1-pt(0.5,17))
```

Do not reject. 

### 7.5

What we know is that $n=36$, so $\sqrt{n} = 6$, $t^{\ast}_{\text{df}}$ is given by

```{r}
(t_ast <- -qt((1-0.95)/2,35))
```

and that 

$$
\begin{align}
\bar{x} - 2.03 \frac{s}{6} = 18.985, \\
\bar{x} + 2.03 \frac{s}{6} = 21.015
\end{align}
$$

This is a system of two equations in two unknowns, that is, $\bar{x}$ and $s$.  An easy way to solve this in R is as follows:

```{r}
A <- matrix(c(1,-2.03/6,1,2.03/6),2,2,byrow = TRUE)
b <- c(18.985,21.015)
solve(A,b)
```

We can check this:

```{r}
x_bar <- 20
s <- 3
(x_bar - 2.03 * (s/6))
(x_bar + 2.03 * (s/6))
```



